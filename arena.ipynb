{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arena for models to take on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "A competitor model will have access to `training_set`, and evaluated on `test_set`.\n",
    "Both are lists of 10 tensors of shape `N x 28 x 28`, where `N` is the number of photos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision.all import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('/home/michael-p/misc_projects/mnist_averages/data/mnist_png'),\n",
       " (#2) [Path('/home/michael-p/misc_projects/mnist_averages/data/mnist_png/testing'),Path('/home/michael-p/misc_projects/mnist_averages/data/mnist_png/training')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_folder = Path(os.getcwd())\n",
    "path = untar_data(URLs.MNIST, current_folder/\"data\", current_folder/\"data\")\n",
    "path, path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['torch.Size([5923, 28, 28]) ', 'torch.Size([6742, 28, 28]) ', 'torch.Size([5958, 28, 28]) ', 'torch.Size([6131, 28, 28]) ', 'torch.Size([5842, 28, 28]) ', 'torch.Size([5421, 28, 28]) ', 'torch.Size([5918, 28, 28]) ', 'torch.Size([6265, 28, 28]) ', 'torch.Size([5851, 28, 28]) ', 'torch.Size([5949, 28, 28]) ']\n",
      "['torch.Size([980, 28, 28]) ', 'torch.Size([1135, 28, 28]) ', 'torch.Size([1032, 28, 28]) ', 'torch.Size([1010, 28, 28]) ', 'torch.Size([982, 28, 28]) ', 'torch.Size([892, 28, 28]) ', 'torch.Size([958, 28, 28]) ', 'torch.Size([1028, 28, 28]) ', 'torch.Size([974, 28, 28]) ', 'torch.Size([1009, 28, 28]) ']\n"
     ]
    }
   ],
   "source": [
    "def stacked_images_tensor(digit:int, subfolder:str):\n",
    "    digit_path = path/subfolder/str(digit)\n",
    "    digit_images = [tensor(Image.open(filename)) for filename in digit_path.ls()]\n",
    "    return torch.stack(digit_images).float()/255\n",
    "\n",
    "training_set = [stacked_images_tensor(d,\"training\") for d in range(10)]\n",
    "test_set = [stacked_images_tensor(d,\"testing\") for d in range(10)]\n",
    "\n",
    "print([f\"{t.shape} \" for t in training_set])\n",
    "print([f\"{t.shape} \" for t in test_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arena_types import MNISTCompetitor\n",
    "\n",
    "def evaluate(model:MNISTCompetitor):\n",
    "    print(f\"'{model.get_name()}':\")\n",
    "    model.train_on(training_set)\n",
    "    preds = model.get_predictions(test_set)\n",
    "\n",
    "    total_correct, total_len = 0, 0\n",
    "    for digit, pred_for_digit in enumerate(preds):\n",
    "        correct = sum([p==digit for p in pred_for_digit])\n",
    "        total_correct += correct\n",
    "        total_len += len(pred_for_digit)\n",
    "        accuracy = correct/len(pred_for_digit)\n",
    "        print(f\"\\t{digit}: {accuracy:.4f}\")\n",
    "    print(f\"\\ntotal accuracy: {total_correct/total_len:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model: comparing to average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'BaselineAverage':\n",
      "\t0: 0.8959\n",
      "\t1: 0.9621\n",
      "\t2: 0.7568\n",
      "\t3: 0.8059\n",
      "\t4: 0.8259\n",
      "\t5: 0.6861\n",
      "\t6: 0.8633\n",
      "\t7: 0.8327\n",
      "\t8: 0.7372\n",
      "\t9: 0.8067\n",
      "\n",
      "total accuracy: 0.82030\n"
     ]
    }
   ],
   "source": [
    "from model_baseline_average import BaselineAverage\n",
    "\n",
    "evaluate(BaselineAverage(F.mse_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1f939cc381e0fc3af4a8a1b7418d5265e3efb0bbb350b3e606529485a7c6f46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
